{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c85464bd",
   "metadata": {},
   "source": [
    "# fetching Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1b9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f253c0c",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49747339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL          65     8450   Pave    NA      Reg   \n",
       "1   2          20       RL          80     9600   Pave    NA      Reg   \n",
       "2   3          60       RL          68    11250   Pave    NA      IR1   \n",
       "3   4          70       RL          60     9550   Pave    NA      IR1   \n",
       "4   5          60       RL          84    14260   Pave    NA      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0     NA    NA          NA       0      2   \n",
       "1         Lvl    AllPub  ...        0     NA    NA          NA       0      5   \n",
       "2         Lvl    AllPub  ...        0     NA    NA          NA       0      9   \n",
       "3         Lvl    AllPub  ...        0     NA    NA          NA       0      2   \n",
       "4         Lvl    AllPub  ...        0     NA    NA          NA       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv', keep_default_na=False)\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaef626",
   "metadata": {},
   "source": [
    " # Getting Dataframe Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee384279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033d002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()[df_train.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446038ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={'MSSubClass':[\"\",\"NA\",'NaN'],'MSZoning':[\"\",\"NA\",'NaN'],'LotFrontage':[\"\",\"NA\",'NaN'],'LotArea':[\"\",\"NA\",'NaN'],\n",
    "     'Street':[\"\",\"NA\",'NaN'],'Alley':[\"\",\"NaN\"],'LotShape':[\"\",\"NA\",\"NaN\"],'LandContour':[\"\",\"NA\",'NaN'],\n",
    "     'Utilities':[\"\",\"NA\",'NaN'],'LotConfig':[\"\",\"NA\",\"NaN\"],'LandSlope':[\"\",\"NA\",\"NaN\"],'Neighborhood':[\"\",\"NA\",\"NaN\"],\n",
    "     'Condition1':[\"\",\"NA\",\"NaN\"], 'Condition2':[\"\",\"NA\",\"NaN\"], 'BldgType':[\"\",\"NA\",\"NaN\"], 'HouseStyle':[\"\",\"NA\",\"NaN\"],\n",
    "     'OverallQual':[\"\",\"NA\",\"NaN\"], 'OverallCond':[\"\",\"NA\",\"NaN\"], 'YearBuilt':[\"\",\"NA\",'NaN'], 'YearRemodAdd':[\"\",\"NA\",'NaN'],\n",
    "     'RoofStyle':[\"\",\"NA\",'NaN'], 'RoofMatl':[\"\",\"NA\",'NaN'], 'Exterior1st':[\"\",\"NA\",'NaN'], 'Exterior2nd':[\"\",\"NA\",'NaN'],\n",
    "     'MasVnrType':[\"\",\"NA\",'NaN'], 'MasVnrArea':[\"\",\"NA\",'NaN'], 'ExterQual':[\"\",\"NA\",'NaN'], 'ExterCond':[\"\",\"NA\",'NaN'],\n",
    "     'Foundation':[\"\",\"NA\",'NaN'], 'BsmtQual':[\"\",'NaN'], 'BsmtCond':[\"\",'NaN'],'BsmtExposure':[\"\",'NaN'],\n",
    "     'BsmtFinType1':[\"\",'NaN'],'BsmtFinType2':[\"\",'NaN'],'BsmtFinSF1':[\"\",\"NA\",'NaN'], 'BsmtFinSF2':[\"\",\"NA\",'NaN'],\n",
    "     'BsmtUnfSF':[\"\",\"NA\",'NaN'], 'TotalBsmtSF':[\"\",\"NA\",'NaN'], 'Heating':[\"\",\"NA\",'NaN'], 'HeatingQC':[\"\",\"NA\",'NaN'],\n",
    "     'CentralAir':[\"\",\"NA\",'NaN'],'Electrical':[\"\",\"NA\",'NaN'], '1stFlrSF':[\"\",\"NA\",'NaN'], '2ndFlrSF':[\"\",\"NA\",'NaN'],\n",
    "     'LowQualFinSF':[\"\",\"NA\",'NaN'], 'GrLivArea':[\"\",\"NA\",'NaN'], 'BsmtFullBath':[\"\",\"NA\",'NaN'], 'BsmtHalfBath':[\"\",\"NA\",'NaN'],\n",
    "     'FullBath':[\"\",\"NA\",'NaN'], 'HalfBath':[\"\",\"NA\",'NaN'], 'Bedroom':[\"\",\"NA\",'NaN'], 'Kitchen':[\"\",\"NA\",'NaN'],\n",
    "     'KitchenQual':[\"\",\"NA\",'NaN'], 'TotRmsAbvGrd':[\"\",\"NA\",'NaN'], 'Functional':[\"\",\"NA\",'NaN'], 'Fireplaces':[\"\",\"NA\",'NaN'],\n",
    "     'FireplaceQu':[\"\",'NaN'],'GarageType':[\"\",'NaN'],'GarageYrBlt':[\"\",\"NA\",'NaN'],'GarageFinish':[\"\",'NaN'],\n",
    "     'GarageCars':[\"\",\"NA\",'NaN'], 'GarageArea':[\"\",\"NA\",'NaN'], 'GarageQual':[\"\",'NaN'],'GarageCond':[\"\",'NaN'],\n",
    "     'PavedDrive':[\"\",\"NA\",'NaN'], 'WoodDeckSF':[\"\",\"NA\",'NaN'],'OpenPorchSF':[\"\",\"NA\",'NaN'], 'EnclosedPorch':[\"\",\"NA\",'NaN'],\n",
    "     '3SsnPorch':[\"\",\"NA\",'NaN'], 'ScreenPorch':[\"\",\"NA\",'NaN'], 'PoolArea':[\"\",\"NA\",\"NaN\"], 'PoolQC':[\"\",\"NaN\"],\n",
    "     'Fence':[\"\",\"NaN\"],'MiscFeature':[\"\",\"NaN\"],'MiscVal':[\"\",\"NA\",\"NaN\"], 'MoSold':[\"\",\"NA\",\"NaN\"],\n",
    "     'YrSold':[\"\",\"NA\",\"NaN\"],'SaleType':[\"\",\"NA\",\"NaN\"],'SaleCondition':[\"\",\"NA\",\"NaN\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "926fb58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', na_values=dic, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9051926b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NA      1369\n",
       "Grvl      50\n",
       "Pave      41\n",
       "Name: Alley, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Alley\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "044790fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['LotFrontage'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64fdc889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['LotArea'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "762c10ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    259\n",
       "MasVnrType       8\n",
       "MasVnrArea       8\n",
       "Electrical       1\n",
       "GarageYrBlt     81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()[df_train.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae189b",
   "metadata": {},
   "source": [
    "# find numeric and non numeric cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f66b12ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = list(df_train.select_dtypes(exclude='object').columns)\n",
    "num_cols.remove('SalePrice')\n",
    "num_cols.remove('Id')\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3252cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = list(df_train.select_dtypes(include='object', exclude='float64').columns)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c30c030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NWAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSZoning Street Alley LotShape LandContour Utilities LotConfig LandSlope  \\\n",
       "0          RL   Pave    NA      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1          RL   Pave    NA      Reg         Lvl    AllPub       FR2       Gtl   \n",
       "2          RL   Pave    NA      IR1         Lvl    AllPub    Inside       Gtl   \n",
       "3          RL   Pave    NA      IR1         Lvl    AllPub    Corner       Gtl   \n",
       "4          RL   Pave    NA      IR1         Lvl    AllPub       FR2       Gtl   \n",
       "...       ...    ...   ...      ...         ...       ...       ...       ...   \n",
       "1455       RL   Pave    NA      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1456       RL   Pave    NA      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1457       RL   Pave    NA      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1458       RL   Pave    NA      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1459       RL   Pave    NA      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "\n",
       "     Neighborhood Condition1  ... GarageType GarageFinish GarageQual  \\\n",
       "0         CollgCr       Norm  ...     Attchd          RFn         TA   \n",
       "1         Veenker      Feedr  ...     Attchd          RFn         TA   \n",
       "2         CollgCr       Norm  ...     Attchd          RFn         TA   \n",
       "3         Crawfor       Norm  ...     Detchd          Unf         TA   \n",
       "4         NoRidge       Norm  ...     Attchd          RFn         TA   \n",
       "...           ...        ...  ...        ...          ...        ...   \n",
       "1455      Gilbert       Norm  ...     Attchd          RFn         TA   \n",
       "1456       NWAmes       Norm  ...     Attchd          Unf         TA   \n",
       "1457      Crawfor       Norm  ...     Attchd          RFn         TA   \n",
       "1458        NAmes       Norm  ...     Attchd          Unf         TA   \n",
       "1459      Edwards       Norm  ...     Attchd          Fin         TA   \n",
       "\n",
       "     GarageCond PavedDrive PoolQC  Fence MiscFeature SaleType SaleCondition  \n",
       "0            TA          Y     NA     NA          NA       WD        Normal  \n",
       "1            TA          Y     NA     NA          NA       WD        Normal  \n",
       "2            TA          Y     NA     NA          NA       WD        Normal  \n",
       "3            TA          Y     NA     NA          NA       WD       Abnorml  \n",
       "4            TA          Y     NA     NA          NA       WD        Normal  \n",
       "...         ...        ...    ...    ...         ...      ...           ...  \n",
       "1455         TA          Y     NA     NA          NA       WD        Normal  \n",
       "1456         TA          Y     NA  MnPrv          NA       WD        Normal  \n",
       "1457         TA          Y     NA  GdPrv        Shed       WD        Normal  \n",
       "1458         TA          Y     NA     NA          NA       WD        Normal  \n",
       "1459         TA          Y     NA     NA          NA       WD        Normal  \n",
       "\n",
       "[1460 rows x 43 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c8818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b2b20c4",
   "metadata": {},
   "source": [
    "# Filling missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c142b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43f9ce38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='most_frequent')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer_num.fit(df_train[num_cols])\n",
    "imputer_cat.fit(df_train[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02d06e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[num_cols] = imputer_num.transform(df_train[num_cols])\n",
    "df_train[cat_cols] = imputer_cat.transform(df_train[cat_cols])\n",
    "\n",
    "df_test[num_cols] = imputer_num.transform(df_test[num_cols])\n",
    "df_test[cat_cols] = imputer_cat.transform(df_test[cat_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55db8b",
   "metadata": {},
   "source": [
    "# check filled or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44b9690e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()[df_train.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f113dcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MSZoning         0\n",
       " Street           0\n",
       " Alley            0\n",
       " LotShape         0\n",
       " LandContour      0\n",
       " Utilities        0\n",
       " LotConfig        0\n",
       " LandSlope        0\n",
       " Neighborhood     0\n",
       " Condition1       0\n",
       " Condition2       0\n",
       " BldgType         0\n",
       " HouseStyle       0\n",
       " RoofStyle        0\n",
       " RoofMatl         0\n",
       " Exterior1st      0\n",
       " Exterior2nd      0\n",
       " MasVnrType       0\n",
       " ExterQual        0\n",
       " ExterCond        0\n",
       " Foundation       0\n",
       " BsmtQual         0\n",
       " BsmtCond         0\n",
       " BsmtExposure     0\n",
       " BsmtFinType1     0\n",
       " BsmtFinType2     0\n",
       " Heating          0\n",
       " HeatingQC        0\n",
       " CentralAir       0\n",
       " Electrical       0\n",
       " KitchenQual      0\n",
       " Functional       0\n",
       " FireplaceQu      0\n",
       " GarageType       0\n",
       " GarageFinish     0\n",
       " GarageQual       0\n",
       " GarageCond       0\n",
       " PavedDrive       0\n",
       " PoolQC           0\n",
       " Fence            0\n",
       " MiscFeature      0\n",
       " SaleType         0\n",
       " SaleCondition    0\n",
       " dtype: int64,\n",
       " MSSubClass       0\n",
       " LotFrontage      0\n",
       " LotArea          0\n",
       " OverallQual      0\n",
       " OverallCond      0\n",
       " YearBuilt        0\n",
       " YearRemodAdd     0\n",
       " MasVnrArea       0\n",
       " BsmtFinSF1       0\n",
       " BsmtFinSF2       0\n",
       " BsmtUnfSF        0\n",
       " TotalBsmtSF      0\n",
       " 1stFlrSF         0\n",
       " 2ndFlrSF         0\n",
       " LowQualFinSF     0\n",
       " GrLivArea        0\n",
       " BsmtFullBath     0\n",
       " BsmtHalfBath     0\n",
       " FullBath         0\n",
       " HalfBath         0\n",
       " BedroomAbvGr     0\n",
       " KitchenAbvGr     0\n",
       " TotRmsAbvGrd     0\n",
       " Fireplaces       0\n",
       " GarageYrBlt      0\n",
       " GarageCars       0\n",
       " GarageArea       0\n",
       " WoodDeckSF       0\n",
       " OpenPorchSF      0\n",
       " EnclosedPorch    0\n",
       " 3SsnPorch        0\n",
       " ScreenPorch      0\n",
       " PoolArea         0\n",
       " MiscVal          0\n",
       " MoSold           0\n",
       " YrSold           0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[cat_cols].isna().sum() , df_train[num_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c0310b",
   "metadata": {},
   "source": [
    "# using cat cols feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc9285c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06fbd6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore', sparse=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
    "ohe.fit(df_train[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "018e192b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x0_C (all)',\n",
       " 'x0_FV',\n",
       " 'x0_RH',\n",
       " 'x0_RL',\n",
       " 'x0_RM',\n",
       " 'x1_Grvl',\n",
       " 'x1_Pave',\n",
       " 'x2_Grvl',\n",
       " 'x2_NA',\n",
       " 'x2_Pave',\n",
       " 'x3_IR1',\n",
       " 'x3_IR2',\n",
       " 'x3_IR3',\n",
       " 'x3_Reg',\n",
       " 'x4_Bnk',\n",
       " 'x4_HLS',\n",
       " 'x4_Low',\n",
       " 'x4_Lvl',\n",
       " 'x5_AllPub',\n",
       " 'x5_NoSeWa',\n",
       " 'x6_Corner',\n",
       " 'x6_CulDSac',\n",
       " 'x6_FR2',\n",
       " 'x6_FR3',\n",
       " 'x6_Inside',\n",
       " 'x7_Gtl',\n",
       " 'x7_Mod',\n",
       " 'x7_Sev',\n",
       " 'x8_Blmngtn',\n",
       " 'x8_Blueste',\n",
       " 'x8_BrDale',\n",
       " 'x8_BrkSide',\n",
       " 'x8_ClearCr',\n",
       " 'x8_CollgCr',\n",
       " 'x8_Crawfor',\n",
       " 'x8_Edwards',\n",
       " 'x8_Gilbert',\n",
       " 'x8_IDOTRR',\n",
       " 'x8_MeadowV',\n",
       " 'x8_Mitchel',\n",
       " 'x8_NAmes',\n",
       " 'x8_NPkVill',\n",
       " 'x8_NWAmes',\n",
       " 'x8_NoRidge',\n",
       " 'x8_NridgHt',\n",
       " 'x8_OldTown',\n",
       " 'x8_SWISU',\n",
       " 'x8_Sawyer',\n",
       " 'x8_SawyerW',\n",
       " 'x8_Somerst',\n",
       " 'x8_StoneBr',\n",
       " 'x8_Timber',\n",
       " 'x8_Veenker',\n",
       " 'x9_Artery',\n",
       " 'x9_Feedr',\n",
       " 'x9_Norm',\n",
       " 'x9_PosA',\n",
       " 'x9_PosN',\n",
       " 'x9_RRAe',\n",
       " 'x9_RRAn',\n",
       " 'x9_RRNe',\n",
       " 'x9_RRNn',\n",
       " 'x10_Artery',\n",
       " 'x10_Feedr',\n",
       " 'x10_Norm',\n",
       " 'x10_PosA',\n",
       " 'x10_PosN',\n",
       " 'x10_RRAe',\n",
       " 'x10_RRAn',\n",
       " 'x10_RRNn',\n",
       " 'x11_1Fam',\n",
       " 'x11_2fmCon',\n",
       " 'x11_Duplex',\n",
       " 'x11_Twnhs',\n",
       " 'x11_TwnhsE',\n",
       " 'x12_1.5Fin',\n",
       " 'x12_1.5Unf',\n",
       " 'x12_1Story',\n",
       " 'x12_2.5Fin',\n",
       " 'x12_2.5Unf',\n",
       " 'x12_2Story',\n",
       " 'x12_SFoyer',\n",
       " 'x12_SLvl',\n",
       " 'x13_Flat',\n",
       " 'x13_Gable',\n",
       " 'x13_Gambrel',\n",
       " 'x13_Hip',\n",
       " 'x13_Mansard',\n",
       " 'x13_Shed',\n",
       " 'x14_ClyTile',\n",
       " 'x14_CompShg',\n",
       " 'x14_Membran',\n",
       " 'x14_Metal',\n",
       " 'x14_Roll',\n",
       " 'x14_Tar&Grv',\n",
       " 'x14_WdShake',\n",
       " 'x14_WdShngl',\n",
       " 'x15_AsbShng',\n",
       " 'x15_AsphShn',\n",
       " 'x15_BrkComm',\n",
       " 'x15_BrkFace',\n",
       " 'x15_CBlock',\n",
       " 'x15_CemntBd',\n",
       " 'x15_HdBoard',\n",
       " 'x15_ImStucc',\n",
       " 'x15_MetalSd',\n",
       " 'x15_Plywood',\n",
       " 'x15_Stone',\n",
       " 'x15_Stucco',\n",
       " 'x15_VinylSd',\n",
       " 'x15_Wd Sdng',\n",
       " 'x15_WdShing',\n",
       " 'x16_AsbShng',\n",
       " 'x16_AsphShn',\n",
       " 'x16_Brk Cmn',\n",
       " 'x16_BrkFace',\n",
       " 'x16_CBlock',\n",
       " 'x16_CmentBd',\n",
       " 'x16_HdBoard',\n",
       " 'x16_ImStucc',\n",
       " 'x16_MetalSd',\n",
       " 'x16_Other',\n",
       " 'x16_Plywood',\n",
       " 'x16_Stone',\n",
       " 'x16_Stucco',\n",
       " 'x16_VinylSd',\n",
       " 'x16_Wd Sdng',\n",
       " 'x16_Wd Shng',\n",
       " 'x17_BrkCmn',\n",
       " 'x17_BrkFace',\n",
       " 'x17_None',\n",
       " 'x17_Stone',\n",
       " 'x18_Ex',\n",
       " 'x18_Fa',\n",
       " 'x18_Gd',\n",
       " 'x18_TA',\n",
       " 'x19_Ex',\n",
       " 'x19_Fa',\n",
       " 'x19_Gd',\n",
       " 'x19_Po',\n",
       " 'x19_TA',\n",
       " 'x20_BrkTil',\n",
       " 'x20_CBlock',\n",
       " 'x20_PConc',\n",
       " 'x20_Slab',\n",
       " 'x20_Stone',\n",
       " 'x20_Wood',\n",
       " 'x21_Ex',\n",
       " 'x21_Fa',\n",
       " 'x21_Gd',\n",
       " 'x21_NA',\n",
       " 'x21_TA',\n",
       " 'x22_Fa',\n",
       " 'x22_Gd',\n",
       " 'x22_NA',\n",
       " 'x22_Po',\n",
       " 'x22_TA',\n",
       " 'x23_Av',\n",
       " 'x23_Gd',\n",
       " 'x23_Mn',\n",
       " 'x23_NA',\n",
       " 'x23_No',\n",
       " 'x24_ALQ',\n",
       " 'x24_BLQ',\n",
       " 'x24_GLQ',\n",
       " 'x24_LwQ',\n",
       " 'x24_NA',\n",
       " 'x24_Rec',\n",
       " 'x24_Unf',\n",
       " 'x25_ALQ',\n",
       " 'x25_BLQ',\n",
       " 'x25_GLQ',\n",
       " 'x25_LwQ',\n",
       " 'x25_NA',\n",
       " 'x25_Rec',\n",
       " 'x25_Unf',\n",
       " 'x26_Floor',\n",
       " 'x26_GasA',\n",
       " 'x26_GasW',\n",
       " 'x26_Grav',\n",
       " 'x26_OthW',\n",
       " 'x26_Wall',\n",
       " 'x27_Ex',\n",
       " 'x27_Fa',\n",
       " 'x27_Gd',\n",
       " 'x27_Po',\n",
       " 'x27_TA',\n",
       " 'x28_N',\n",
       " 'x28_Y',\n",
       " 'x29_FuseA',\n",
       " 'x29_FuseF',\n",
       " 'x29_FuseP',\n",
       " 'x29_Mix',\n",
       " 'x29_SBrkr',\n",
       " 'x30_Ex',\n",
       " 'x30_Fa',\n",
       " 'x30_Gd',\n",
       " 'x30_TA',\n",
       " 'x31_Maj1',\n",
       " 'x31_Maj2',\n",
       " 'x31_Min1',\n",
       " 'x31_Min2',\n",
       " 'x31_Mod',\n",
       " 'x31_Sev',\n",
       " 'x31_Typ',\n",
       " 'x32_Ex',\n",
       " 'x32_Fa',\n",
       " 'x32_Gd',\n",
       " 'x32_NA',\n",
       " 'x32_Po',\n",
       " 'x32_TA',\n",
       " 'x33_2Types',\n",
       " 'x33_Attchd',\n",
       " 'x33_Basment',\n",
       " 'x33_BuiltIn',\n",
       " 'x33_CarPort',\n",
       " 'x33_Detchd',\n",
       " 'x33_NA',\n",
       " 'x34_Fin',\n",
       " 'x34_NA',\n",
       " 'x34_RFn',\n",
       " 'x34_Unf',\n",
       " 'x35_Ex',\n",
       " 'x35_Fa',\n",
       " 'x35_Gd',\n",
       " 'x35_NA',\n",
       " 'x35_Po',\n",
       " 'x35_TA',\n",
       " 'x36_Ex',\n",
       " 'x36_Fa',\n",
       " 'x36_Gd',\n",
       " 'x36_NA',\n",
       " 'x36_Po',\n",
       " 'x36_TA',\n",
       " 'x37_N',\n",
       " 'x37_P',\n",
       " 'x37_Y',\n",
       " 'x38_Ex',\n",
       " 'x38_Fa',\n",
       " 'x38_Gd',\n",
       " 'x38_NA',\n",
       " 'x39_GdPrv',\n",
       " 'x39_GdWo',\n",
       " 'x39_MnPrv',\n",
       " 'x39_MnWw',\n",
       " 'x39_NA',\n",
       " 'x40_Gar2',\n",
       " 'x40_NA',\n",
       " 'x40_Othr',\n",
       " 'x40_Shed',\n",
       " 'x40_TenC',\n",
       " 'x41_COD',\n",
       " 'x41_CWD',\n",
       " 'x41_Con',\n",
       " 'x41_ConLD',\n",
       " 'x41_ConLI',\n",
       " 'x41_ConLw',\n",
       " 'x41_New',\n",
       " 'x41_Oth',\n",
       " 'x41_WD',\n",
       " 'x42_Abnorml',\n",
       " 'x42_AdjLand',\n",
       " 'x42_Alloca',\n",
       " 'x42_Family',\n",
       " 'x42_Normal',\n",
       " 'x42_Partial']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = list(ohe.get_feature_names())\n",
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f3f4983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "918af598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_14332\\1785779652.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_test[new_cols] = ohe.transform(df_test[cat_cols])\n"
     ]
    }
   ],
   "source": [
    "df_train[new_cols] = ohe.transform(df_train[cat_cols])\n",
    "df_test[new_cols] = ohe.transform(df_test[cat_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f4d83",
   "metadata": {},
   "source": [
    "# feature reduction on corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62e3395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_col=list(df_train.corr()['SalePrice'][(df_train.corr()['SalePrice']>=0.07)|(df_train.corr()['SalePrice']<=-0.07)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62698a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_col.remove('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "408d87dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6b5cd",
   "metadata": {},
   "source": [
    "# model building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad34a85",
   "metadata": {},
   "source": [
    "# Model 1 : 'GridSearchCV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a190f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be23f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'min_samples_leaf' : [2,3,4,5],\n",
    "         'max_depth' : [2,3,4,5,6],\n",
    "        'n_estimators': [500,1000,1500,1800]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f3261be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=2; total time=   0.6s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=2; total time=   0.5s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=2; total time=   0.4s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=2; total time=   0.5s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=2; total time=   0.4s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=3; total time=   0.4s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=3; total time=   0.4s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=3; total time=   0.4s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=3; total time=   0.4s\n",
      "[CV] END ....................max_depth=2, min_samples_leaf=3; total time=   0.4s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=2; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=2; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=2; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=2; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=2; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=3; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=3; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=3; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=3; total time=   0.6s\n",
      "[CV] END ....................max_depth=3, min_samples_leaf=3; total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [2, 3], 'min_samples_leaf': [2, 3]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = GridSearchCV(RandomForestRegressor(), param_grid=dict1, cv=5, verbose=2)\n",
    "grid_cv.fit(df_train[num_cols+final_col],df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2498101",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_cv.best_estimator_\n",
    "yp = model.predict(df_test[num_cols+final_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "179224c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['SalePrice'] = yp\n",
    "df_test[['Id','SalePrice']].to_csv('sub3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24d966",
   "metadata": {},
   "source": [
    "# BEST SCORE = 0.165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3f99459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = grid_Cv.best_estimator_\n",
    "#yp = model.predict(df_test[num_cols + new_cols])\n",
    "#df_submission6 = pd.DataFrame({'PassengerId':df_test['PassengerId'], 'Survived':yp})\n",
    "#df_submission6.to_csv('shivnehal_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a816af3e",
   "metadata": {},
   "source": [
    "# model 2 : 'GradientBoostingRegressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27938df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(n_estimators=1500,max_depth=5,min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca381c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=5, min_samples_leaf=5, n_estimators=1500)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df_train[num_cols+final_col],df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "025539ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model.predict(df_test[num_cols+final_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d4d7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['SalePrice'] = yp\n",
    "df_test[['Id','SalePrice']].to_csv('GBR1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb07dce",
   "metadata": {},
   "source": [
    "# BEST SCORE = 0.132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e88fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c13f20a",
   "metadata": {},
   "source": [
    "# Model 3 : 'xgboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bd480c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\shiva\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shiva\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\shiva\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cd17990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ee9368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(n_estimators=200,max_depth=5,min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f505f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:01:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy='depthwise', importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=5, max_leaves=0, min_child_weight=1, min_samples_leaf=5,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=200, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', ...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.fit(df_train[final_col], df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d5cea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model_xgb.predict(df_test[final_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dfcb06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['SalePrice'] = yp\n",
    "df_test[['Id','SalePrice']].to_csv('shiva77.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94305309",
   "metadata": {},
   "source": [
    "# BEST SCORE = 0.143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab2037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eacbca0f",
   "metadata": {},
   "source": [
    "# model 4 : 'GradientBoostingRegressor Tunning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b736ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19a341b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[CV] END ..max_depth=2, min_samples_leaf=2, n_estimators=500; total time=   1.7s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=2, n_estimators=500; total time=   1.6s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=2, n_estimators=500; total time=   1.6s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=2, n_estimators=500; total time=   1.6s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=2, n_estimators=500; total time=   1.6s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1800; total time=   6.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1800; total time=   6.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1800; total time=   6.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1800; total time=   6.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=2, n_estimators=1800; total time=   6.3s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=3, n_estimators=500; total time=   1.7s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=3, n_estimators=500; total time=   1.7s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=3, n_estimators=500; total time=   1.6s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=3, n_estimators=500; total time=   1.7s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=3, n_estimators=500; total time=   1.6s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1500; total time=   5.5s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1800; total time=   6.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1800; total time=   6.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1800; total time=   6.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1800; total time=   6.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=3, n_estimators=1800; total time=   6.2s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=4, n_estimators=500; total time=   1.7s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=4, n_estimators=500; total time=   1.7s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=4, n_estimators=500; total time=   1.7s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=4, n_estimators=500; total time=   1.7s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=4, n_estimators=500; total time=   1.8s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1000; total time=   3.6s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1000; total time=   3.4s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1800; total time=   6.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1800; total time=   6.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1800; total time=   6.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1800; total time=   6.5s\n",
      "[CV] END .max_depth=2, min_samples_leaf=4, n_estimators=1800; total time=   6.1s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=5, n_estimators=500; total time=   1.6s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=5, n_estimators=500; total time=   1.6s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=5, n_estimators=500; total time=   1.6s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=5, n_estimators=500; total time=   1.6s\n",
      "[CV] END ..max_depth=2, min_samples_leaf=5, n_estimators=500; total time=   1.6s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1000; total time=   3.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1000; total time=   3.4s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1000; total time=   3.5s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1000; total time=   3.4s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1500; total time=   5.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1500; total time=   5.3s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1500; total time=   5.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1800; total time=   6.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1800; total time=   6.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1800; total time=   6.1s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1800; total time=   6.2s\n",
      "[CV] END .max_depth=2, min_samples_leaf=5, n_estimators=1800; total time=   6.2s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=2, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=2, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=2, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=2, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=2, n_estimators=500; total time=   2.5s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1000; total time=   5.1s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1000; total time=   5.1s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1000; total time=   5.1s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1800; total time=   9.3s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1800; total time=   9.3s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1800; total time=   9.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=2, n_estimators=1800; total time=   9.0s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=3, n_estimators=500; total time=   2.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=3, n_estimators=500; total time=   2.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=3, n_estimators=500; total time=   2.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=3, n_estimators=500; total time=   2.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=3, n_estimators=500; total time=   2.4s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1000; total time=   4.9s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1500; total time=   7.5s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1500; total time=   7.4s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1500; total time=   7.5s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1500; total time=   7.8s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1800; total time=   9.3s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=3, n_estimators=1800; total time=   9.2s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=4, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=4, n_estimators=500; total time=   2.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=4, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=4, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=4, n_estimators=500; total time=   2.5s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1000; total time=   5.1s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1800; total time=   9.1s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=4, n_estimators=1800; total time=   9.1s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=500; total time=   2.5s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1000; total time=   5.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1000; total time=   5.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1000; total time=   5.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1000; total time=   5.0s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1500; total time=   7.5s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1500; total time=   7.8s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1500; total time=   7.7s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1500; total time=   7.8s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1800; total time=   9.2s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1800; total time=   9.3s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1800; total time=   9.4s\n",
      "[CV] END .max_depth=3, min_samples_leaf=5, n_estimators=1800; total time=   9.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1000; total time=   6.9s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1000; total time=   6.7s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1000; total time=   6.7s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1500; total time=  10.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1500; total time=  10.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1500; total time=  10.3s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1500; total time=  10.1s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1500; total time=  10.0s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1800; total time=  12.2s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1800; total time=  12.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1800; total time=  12.3s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1800; total time=  12.2s\n",
      "[CV] END .max_depth=4, min_samples_leaf=2, n_estimators=1800; total time=  12.2s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=3, n_estimators=500; total time=   3.3s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=3, n_estimators=500; total time=   3.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=3, n_estimators=500; total time=   3.3s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=3, n_estimators=500; total time=   3.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=3, n_estimators=500; total time=   3.5s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1000; total time=   6.9s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1000; total time=   6.7s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1000; total time=   6.6s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1500; total time=  10.3s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1500; total time=  10.2s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1500; total time=  10.1s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1500; total time=  10.2s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1500; total time=  10.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1800; total time=  12.1s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1800; total time=  12.2s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1800; total time=  12.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1800; total time=  12.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=3, n_estimators=1800; total time=  12.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=4, n_estimators=500; total time=   3.2s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=4, n_estimators=500; total time=   3.3s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=4, n_estimators=500; total time=   3.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=4, n_estimators=500; total time=   3.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=4, n_estimators=500; total time=   3.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1000; total time=   6.9s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1500; total time=  10.2s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1500; total time=   9.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1500; total time=  10.0s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1500; total time=  10.3s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1500; total time=  10.3s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1800; total time=  12.1s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1800; total time=  12.2s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1800; total time=  12.1s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1800; total time=  12.1s\n",
      "[CV] END .max_depth=4, min_samples_leaf=4, n_estimators=1800; total time=  12.0s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1000; total time=   6.6s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1000; total time=   6.7s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1000; total time=   6.6s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1000; total time=   6.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1500; total time=  10.1s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1500; total time=  10.1s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1500; total time=  10.0s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1500; total time=  10.4s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1500; total time=   9.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1800; total time=  11.9s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1800; total time=  11.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1800; total time=  11.9s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1800; total time=  11.8s\n",
      "[CV] END .max_depth=4, min_samples_leaf=5, n_estimators=1800; total time=  11.8s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=500; total time=   4.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=500; total time=   4.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=500; total time=   4.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=500; total time=   4.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=2, n_estimators=500; total time=   4.0s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1000; total time=   8.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1000; total time=   8.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1000; total time=   8.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1000; total time=   8.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1000; total time=   8.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1500; total time=  12.3s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1500; total time=  12.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1500; total time=  12.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1500; total time=  12.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1500; total time=  12.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1800; total time=  15.0s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1800; total time=  14.9s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1800; total time=  14.8s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1800; total time=  15.4s\n",
      "[CV] END .max_depth=5, min_samples_leaf=2, n_estimators=1800; total time=  15.7s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=3, n_estimators=500; total time=   4.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=3, n_estimators=500; total time=   4.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=3, n_estimators=500; total time=   4.3s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=3, n_estimators=500; total time=   4.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=3, n_estimators=500; total time=   4.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   8.5s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   8.6s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   8.6s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   8.8s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   8.9s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1500; total time=  13.4s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1500; total time=  13.4s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1500; total time=  13.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1500; total time=  13.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1500; total time=  12.8s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1800; total time=  14.9s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1800; total time=  14.6s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1800; total time=  15.4s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1800; total time=  15.8s\n",
      "[CV] END .max_depth=5, min_samples_leaf=3, n_estimators=1800; total time=  15.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=500; total time=   4.3s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=500; total time=   4.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=500; total time=   4.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=500; total time=   4.1s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=4, n_estimators=500; total time=   4.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1000; total time=   8.4s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1000; total time=   8.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1000; total time=   8.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1000; total time=   8.2s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1000; total time=   8.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1500; total time=  12.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1500; total time=  12.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1500; total time=  12.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1500; total time=  12.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1500; total time=  12.3s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1800; total time=  14.8s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1800; total time=  14.5s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1800; total time=  14.6s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1800; total time=  14.5s\n",
      "[CV] END .max_depth=5, min_samples_leaf=4, n_estimators=1800; total time=  14.7s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=5, n_estimators=500; total time=   4.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=5, n_estimators=500; total time=   3.9s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=5, n_estimators=500; total time=   4.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=5, n_estimators=500; total time=   4.0s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=5, n_estimators=500; total time=   4.0s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   8.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   8.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   8.0s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   8.0s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   8.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1500; total time=  12.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1500; total time=  14.0s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1500; total time=  18.1s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1500; total time=  12.4s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1500; total time=  12.5s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1800; total time=  14.6s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1800; total time=  14.6s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1800; total time=  14.7s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1800; total time=  14.5s\n",
      "[CV] END .max_depth=5, min_samples_leaf=5, n_estimators=1800; total time=  14.7s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=2, n_estimators=500; total time=   5.0s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=2, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=2, n_estimators=500; total time=   4.9s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=2, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=2, n_estimators=500; total time=   4.9s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1000; total time=   9.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1000; total time=   9.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1000; total time=   9.9s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1500; total time=  14.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1500; total time=  14.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1500; total time=  14.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1500; total time=  14.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1500; total time=  14.9s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1800; total time=  17.5s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1800; total time=  17.5s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1800; total time=  17.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1800; total time=  17.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=2, n_estimators=1800; total time=  17.6s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=3, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=3, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=3, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=3, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=3, n_estimators=500; total time=   4.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1000; total time=   9.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1000; total time=   9.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1500; total time=  14.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1500; total time=  14.5s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1500; total time=  14.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1500; total time=  14.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1500; total time=  14.9s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1800; total time=  17.9s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1800; total time=  18.2s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1800; total time=  18.5s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1800; total time=  18.4s\n",
      "[CV] END .max_depth=6, min_samples_leaf=3, n_estimators=1800; total time=  17.6s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=4, n_estimators=500; total time=   5.0s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=4, n_estimators=500; total time=   5.0s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=4, n_estimators=500; total time=   4.9s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=4, n_estimators=500; total time=   5.1s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=4, n_estimators=500; total time=   5.0s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1000; total time=   9.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1000; total time=   9.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1000; total time=   9.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1500; total time=  14.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1500; total time=  14.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1500; total time=  15.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1500; total time=  14.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1500; total time=  14.5s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1800; total time=  17.9s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1800; total time=  18.0s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1800; total time=  17.4s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1800; total time=  17.9s\n",
      "[CV] END .max_depth=6, min_samples_leaf=4, n_estimators=1800; total time=  17.6s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=5, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=5, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=5, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=5, n_estimators=500; total time=   4.8s\n",
      "[CV] END ..max_depth=6, min_samples_leaf=5, n_estimators=500; total time=   4.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1000; total time=   9.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1000; total time=   9.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1000; total time=   9.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1500; total time=  14.4s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1500; total time=  14.3s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1500; total time=  14.6s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1500; total time=  14.7s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1500; total time=  14.8s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1800; total time=  18.3s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1800; total time=  17.5s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1800; total time=  17.3s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1800; total time=  17.4s\n",
      "[CV] END .max_depth=6, min_samples_leaf=5, n_estimators=1800; total time=  17.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6],\n",
       "                         'min_samples_leaf': [2, 3, 4, 5],\n",
       "                         'n_estimators': [500, 1000, 1500, 1800]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = GridSearchCV(GradientBoostingRegressor(), param_grid=dict1, cv=5, verbose=2)\n",
    "grid_cv.fit(df_train[final_col],df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b7528d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Gbr = grid_cv.best_estimator_\n",
    "yp = model_Gbr.predict(df_test[final_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e43e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['SalePrice'] = yp\n",
    "df_test[['Id','SalePrice']].to_csv('lasttunegradient.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907136a",
   "metadata": {},
   "source": [
    "# BEST SCORE = 0.136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455f66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
